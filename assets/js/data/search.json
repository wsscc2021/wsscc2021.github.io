[ { "title": "Kubernetes - Cluster Autoscaler + OverProvisioning", "url": "/posts/Kubernetes-Cluster-Autoscaler-+-OverProvisioning/", "categories": "DevOps", "tags": "DevOps, Kubernetes", "date": "2021-10-27 15:00:00 +0900", "snippet": "컨테이너 생성 시간 vs VM 생성 시간컨테이너는 VM보다 경량적인 isolation 기술로써, VM보다 이미지 크기가 작고 빠르게 프로비저닝되는 장점을 가지고 있습니다. 이는 분산 시스템 형태에서 수평적 확장을 수행하는 클라우드 환경에서 더욱 부각됩니다.때문에 일반적으로 클라우드 환경에서는 클라우드 업체에서 제공해주는 VM 위에서 경량의 컨테이너를 오케스트레이션하는 방식으로 운영하게 되는 데, 대략적으로 아래와 같은 구성을 가집니다.(확장 시 VM이 아닌 컨테이너만 생성하여 빠르게 확장합니다.)Cluster Autoscaler위에서 살펴본 것처럼 노드(VM) 위에서 컨테이너를 실행함으로써 프로비저닝 시간을 단축하여 확장의 성능 측면에서 장점을 가질 수 있습니다.하지만 VM의 모든 리소스를 사용하고 있는 상태에서 새로운 파드가 생성되면 스케줄링되지 못하고 pending 상태가 유지되는 현상이 발생합니다. 이러한 경우, 클라우드 업체에 맞는 ClusterAutoScaler를 사용하여 해결할 수 있습니다.일반적으로 ClusterAutoScaler는 리소스가 부족하여 파드를 스케줄링하지 못할 때 노드(VM)을 추가하여 리소스를 확보하는 방식으로 동작합니다. AWS Cluster Auto Scaler: https://docs.aws.amazon.com/ko_kr/eks/latest/userguide/cluster-autoscaler.htmlOver ProvisioningCluster Auto Scaler는 파드가 생성되고 스케줄링할 때 리소스가 부족하다면 새로운 노드를 생성하는 방식으로 동작합니다.즉, 리소스가 부족할 때 생성된 파드는 새로운 노드(VM)가 프로비저닝되는 시간 동안 스케줄링되지 못하고 Pending 상태로 남아있는 문제가 여전히 남아있습니다.이는 아무런 의미가 없는 파드를 낮은 우선순위로 미리 생성함으로써 해결할 수 있습니다. (Over Provisioning)새로운 파드가 생성되었을 때 우선순위가 낮은 빈 파드는 Eviction 되고, 그 자리에 새로운 파드가 스케줄 됩니다.Eviction된 빈 파드를 위해서 Cluster Autoscaler가 동작하여 리소스를 확보합니다.낮은 우선순위를 가지는 빈 파드 만들기PriorityClass를 활용하여 우선순위가 낮은 빈 파드를 생성할 수 있습니다. 아래 예시를 참조합니다.특히, resources 부분의 cpu/memmory 용량과 replica 수를 자신의 시스템에 맞게 적절한 값으로 정의해야 합니다.---apiVersion: scheduling.k8s.io/v1beta1kind: PriorityClassmetadata: name: overprovisioningvalue: -1globalDefault: false---apiVersion: apps/v1kind: Deploymentmetadata: name: overprovisioning namespace: kube-systemspec: replicas: 3 selector: matchLabels: run: overprovisioning template: metadata: labels: run: overprovisioning spec: priorityClassName: overprovisioning containers: - name: reserve-resources image: k8s.gcr.io/pause resources: requests: cpu: 820m memory: 2000Mi결론over provisioning은 수평적 확장을 보다 빠르게 수행할 수 있다는 장점을 가지고 있지만, 리소스 공간을 낭비한다는 단점도 수반합니다. 때문에, 확장성에 큰 비중을 두지 않아도 되는 시스템에서는 over provisioning을 도입하지 않는 것이 더 효율적일 수 있습니다. 언제나 그렇듯 상황에 맞게 기술을 구현하여 사용할 필요가 있습니다." }, { "title": "Kubernetes - Pod 불균형 없애고 가용성 높이기", "url": "/posts/Kubernetes-Pod-%EB%B6%88%EA%B7%A0%ED%98%95-%EC%97%86%EC%95%A0%EA%B3%A0-%EA%B0%80%EC%9A%A9%EC%84%B1-%EB%86%92%EC%9D%B4%EA%B8%B0/", "categories": "DevOps", "tags": "DevOps, Kubernetes", "date": "2021-10-19 16:00:00 +0900", "snippet": "Pod 불균형파드를 생성할 때에 스케줄링에 아무런 제약을 주지 않으면 리소스 공간이 있는 노드에 무분별하게 스케줄링된다. 이러한 스케줄링 방식은 시스템 가용성의 허점을 줄 수 있다. 아래를 살펴보자.서비스가 현재 트래픽을 견디기 위해서 4.0 CPU Core를 필요로 하고, 이를 위해서 2.0 CPU Core 를 가지는 파드를 4대 운영하고 있다고 가정해보자. 그리고, 파드를 생성할 때 스케줄링에 별다른 제약이 없다면, node-A의 리소스 공간이 충분하여 node-A에 3대의 파드가 스케줄링되고, node-B에 1대의 파드가 스케줄링된다. 물론 아무런 장애가 발생하지 않는다면, 이러한 시스템도 정상적으로 운영될 것이다.하지만 node-A에 장애가 생기게 된다면 node-B에는 1대의 파드만 존재하므로 일시적으로 기존 트래픽을 견딜 수 없는 상태가 된다. 이는 가용성이 충분히 확보된 시스템이라고 보기는 어렵다.Pod Topology Spread Constraints위와 같은 문제를 해결하기 위해서는 노드에 고르게 퍼져서 스케줄링되도록 해야한다. 만약 클라우드를 사용하고 있다면 가용영역 및 리전을 고려하여 스케줄링되도록 하여 가용성을 한층 더 높일 수 있을 것이다. 이러한 요구를 만족하기 위해서 파드에 Pod Topology Spread Constraints 을 정의할 수 있다. Pod Topology Spread Constraints을 간략하게 살펴보면, 파드를 스케줄링할 때 각 노드에 labelSelector에 매치되는 파드가 얼마나 할당되어 있는 지를 확인하여 파드 수의 차이(maxskew)가 벌어지지 않도록 적절한 노드를 선택하여 스케줄링한다. 결과적으로 파드가 각 노드에 고르게 퍼져서 스케줄링될 수 있다.topologySpreadConstraints:- maxSkew: 1 topologyKey: &quot;kubernetes.io/hostname&quot; whenUnsatisfiable: &quot;ScheduleAnyway&quot; labelSelector: matchLabels: app.kubernetes.io/name: account-app해당 글은 간략히 필요한 이유와 전체적인 흐름을 이해하는 정도로만 읽으면 좋을 것 같아서, 설정에 대한 내용은 정리하지 않겠습니다. 자세한 설정은 공식 홈페이지를 참조하여 정확하게 구현하는 것이 좋을 것입니다. https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/deschedulerPod Toplogy Spread Constraints 는 기본적으로 스케줄링에 제약을 주는 기능입니다. 즉, 이미 스케줄링된 기존의 파드에게는 적용되지 않습니다. 이는 파드가 scale-in 되면서 파드 불균형이 발생할 수 있음을 의미합니다. scale-in 되는 상황에서도 파드 불균형이 발생하지 않도록 descheduler를 사용할 수 있습니다. https://github.com/kubernetes-sigs/descheduler" }, { "title": "컨테이너 기술 이해하기", "url": "/posts/%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B8%B0%EC%88%A0-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0/", "categories": "DevOps", "tags": "DevOps, Container", "date": "2021-10-08 18:00:00 +0900", "snippet": "Overview이전 글에서 MSA(Micro Service Architecture) 를 이해하였습니다. 컨테이너는 MSA의 시대가 열리면서 굉장히 주목받게된 기술 중에 하나이기 때문에 연관지어 이해할 필요가 있습니다.MSA 에서는 하나의 큰 어플리케이션이 작은 단위의 서비스 여러개로 나뉘고, 각 서비스는 서로에게 영향을 주지않고 운영되어야 하기 때문에 서비스 수 만큼의 독립된 컴퓨터 시스템을 가져야합니다. 기존에는 하나의 컴퓨터 시스템이 필요했다면, MSA에서는 서비스 수 만큼의 여러 컴퓨터 시스템이 필요하게 된 것입니다.그리고 대체로 서비스는 단위가 작지만, 서버로 운영되는 컴퓨터 리소스는 대체로 용량이 크기 때문에 하나의 컴퓨터 리소스로 하나의 컴퓨터 시스템을 운영하는 것이 비효율적이게 됩니다.가상화 기술이러한 문제점을 해결하기 위해서 가상화 기술을 사용할 수 있습니다. 가상화 기술을 사용하면 Hypervisor를 통해 독립된 Guest OS를 실행하고 그 위에서 어플리케이션이 실행되는 방식으로 동작합니다. 결과적으로 하나의 컴퓨터 리소스에서 여러개의 독립된 컴퓨터 시스템을 운영하고 각 시스템 위에서 어플리케이션을 실행시킬 수 있습니다. (*자세하게 살펴보면 전가상화/반가상화로 구분되지만, 최소한의 이해를 위해서 생략하도록 합니다.)가상화 기술의 단점가상화 기술을 통해서 시스템을 독립시킬 수는 있지만 여러 단점도 함께 드러납니다. 그리고 이러한 단점들은 MSA를 운영하는 관점에서 큰 단점으로 부각됩니다. 오버헤드가 크다. Operating System은 사용자가 컴퓨터 자원을 효율적이고 직관적으로 사용할 수 있도록 설계되어 있습니다. 때문에 어플리케이션 실행과 무관하게 사용성을 위한 기능도 포함되어 있고, 이는 불필요하게 서버의 자원을 잡아먹습니다. 서비스의 수가 많아지면 많아질 수록 해당 오버헤드는 더 커지게 되며 큰 규모의 프로젝트에서 단점으로 극명하게 드러납니다. 클라우드 운영 측면에서는 필요한 자원의 크기가 클 수록 프로비저닝에 걸리는 시간이 지연되고 이는 전체적인 성능에도 영향을 줍니다. 성능 감소가 크다. 반가상화/전가상화인지에 따라 방식은 다르지만, Guest OS의 Kernel을 하나 더 거쳐 하드웨어와 통신하기 때문에 시스템 성능이 전체적으로 감소합니다. 컨테이너 기술컨테이너는 namespace, cgroup, chroot와 같은 기능을 활용하여 OS 수준에서 시스템을 격리시키는 기술입니다. 가상화 기술과 같이 시스템을 격리시킬 수 있지만 오버헤드가 적고, 성능 감소가 적어서 MSA를 운영하는 관점에서 큰 관심을 받게 됩니다. 오버헤드가 적다. 시스템 격리를 위해서 Guest OS가 필요없고, 어플리케이션 실행에 필요한 최소한의 기능들만 포함하기 때문에 경량화된 시스템 격리 기술이라고 이야기 합니다. 성능 감소가 적다. 모든 컨테이너는 Host OS의 Kernel을 공유하고, Host OS의 Kernel만을 거쳐 하드웨어와 통신하기 때문에 시스템 성능 감소가 가상화 시스템에 비해 덜 합니다. 컨테이너 기술의 단점하지만 컨테이너 기술은 하나의 커널을 공유하고 리눅스 OS 기능에 의존하기 때문에 몇 가지 단점을 수반합니다. 보안성 하나의 컨테이너에서 보안적인 결함이 발생하여 Host OS의 관리자 계정 권한을 얻는다면, 이를 통해 타 컨테이너에 접근할 수 있습니다. 즉, 한 서비스의 보안 결함이 다른 서비스의 보안성까지 위협합니다. 안정성 만약 하나의 컨테이너에서 kernel에 장애(에러)를 일으킨다면 다른 컨테이너도 Kernel을 사용하는 것에 영향을 줍니다. 이는 가상화 시스템에 비해 불안정적인 요소로 드러납니다. 결론컨테이너는 MSA 를 운영한다면 반드시 이해하고 활용해야할 기술 중에 하나입니다. 하지만, 보안성과 안정성에 이슈가 존재함을 인지하고 있어야 하며 이를 특히 주의하여 컨테이너를 생성하고 관리하여야 합니다.그리고 시스템 격리에 반드시 컨테이너 기술을 사용하는 것이 정답만은 아니라는 것도 알고 있어야 합니다. (서비스가 많지 않고 보안성을 가장 우선시 두는 어플리케이션이라면 가상화 기술을 사용하는 것도 괜찮은 선택지 중 하나입니다.)" }, { "title": "Kubernetes - Healthcheck (liveness-probe, startup-probe, readiness-probe)", "url": "/posts/Kubernetes-Healthcheck-(liveness-probe,-startup-probe,-readiness-probe)/", "categories": "DevOps", "tags": "DevOps, Container, Kubernetes", "date": "2021-10-07 20:30:00 +0900", "snippet": "OverviewKubernetes에서는 pod 의 상태를 확인하기 위해서 liveness-probe, startup-probe, readiness-probe가 사용됩니다. 각각을 살펴보면서 어떻게 활용할지에 대한 고민을 해봅니다. (HTTP, TCP, Exec 3가지 타입의 probe가 존재하지만, 가장 많이 사용되는 HTTP probe 타입으로 진행합니다.)liveness probeliveness probe는 에러가 발생하여 요청을 처리할 수 없는 상태의 pod를 재시작하는 것에 사용됩니다. (Self-Healing)liveness probe는 healthcheck에 실패한 pod를 kill하고, 다시 시작합니다.livenessProbe: httpGet: path: /healthcheck/liveness port: 8080 initialDelaySeconds: 0 # default 0, 어플리케이션이 시작될때까지 기다리는 시간입니다. periodSeconds: 10 # default 10, Healthcheck 요청을 보내는 주기(Interval)입니다. timeoutSeconds: 5 # default 1, Healthcheck 요청의 타임아웃 값입니다. failureThreshold: 3 # default 3, 3번 이상 실패하면 파드를 재시작합니다. successThreshold: 1 # default 1, 1번 이상 성공하면 Running 상태로 넘어갑니다.startup probe파드는 어플리케이션이 시작될 때 까지 요청을 처리하지 못할 수 있습니다. 이 시기에 liveness probe로 파드가 재시작되는 것을 방지하기 위해서 사용됩니다. 이는 initialDelaySeconds 옵션과 흡사하지만, 동적인 것과 정적인 것의 차이를 줄 수 있습니다. initialDelaySeconds는 정적으로 시간을 지정하여 어플리케이션 시작을 기다리지만, startup probe는 동적인 시간 대역을 가져갈 수 있습니다.어플리케이션이 시작되는 데 걸리는 시간이 항상 일정할 수도 있지만, 구성 파일을 로드할 때 발생하는 지연시간, 서버의 리소스 사용률이 높을 경우 발생하는 지연시간 등의 여러 상황들로 인해서 시작되는 시간이 변동될 수 있습니다. 그리고 이러한 경우 startup probe가 유용하게 활용됩니다.startup probe 는 healthcheck에 성공할 때까지 liveness probe, readiness probe를 시작하지 않습니다.livenessProbe: httpGet: path: /healthcheck/liveness port: 8080 initialDelaySeconds: 0 # default 0, 어플리케이션이 시작될때까지 기다리는 시간입니다. periodSeconds: 10 # default 10, Healthcheck 요청을 보내는 주기(Interval)입니다. timeoutSeconds: 5 # default 1, Healthcheck 요청의 타임아웃 값입니다. failureThreshold: 3 # default 3, 3번 이상 실패하면 파드를 재시작합니다. successThreshold: 1 # default 1, 1번 이상 성공하면 Running 상태로 넘어갑니다.startupProbe: httpGet: path: /healthcheck/liveness port: 8080 initialDelaySeconds: 0 # default 0, 어플리케이션이 시작될때까지 기다리는 시간입니다. periodSeconds: 10 # default 10, Healthcheck 요청을 보내는 주기(Interval)입니다. timeoutSeconds: 5 # default 1, Healthcheck 요청의 타임아웃 값입니다. failureThreshold: 6 # default 3, 3번 이상 실패하면 readiness probe, liveness probe를 시작하지 않습니다. successThreshold: 1 # default 1, 1번 이상 성공하면 readiness probe와 liveness probe를 시작합니다.readiness probe파드에 트래픽이 몰려 cpu/memory 사용률이 일정 수준 이상 높아지면 요청을 처리하는 것에 지연이 생기거나 500에러가 발생하여 Healthcheck에 실패할 수 있습니다. 이는 어플리케이션의 에러가 아니며 cpu/memory 사용률을 낮춰주면 자연스럽게 해결되는 문제입니다. 이럴 경우 readiness probe을 활용하여 트래픽을 받지 않음으로써 cpu/memory 사용률을 낮춰주는 역할을 수행할 수 있습니다.readiness probe에 실패한 파드는 요청을 받지 않습니다.readinessProbe: httpGet: path: /healthcheck/readiness port: 8080 initialDelaySeconds: 0 # default 0, 어플리케이션이 시작될때까지 기다리는 시간입니다. periodSeconds: 10 # default 10, Healthcheck 요청을 보내는 주기(Interval)입니다. timeoutSeconds: 5 # default 1, Healthcheck 요청의 타임아웃 값입니다. failureThreshold: 3 # default 3, 3번 이상 실패하면 파드에 요청을 받지 않습니다. successThreshold: 1 # default 1, 1번 이상 성공하면 파드에 요청을 받습니다.readiness probe의 동작을 정확하게 이해하기 위해서는 서비스, 엔드포인트, 파드 리소스의 네트워크 연결이 어떻게 이뤄지는 지 이해해야 합니다.위 그림에서 볼 수 있듯이, 파드는 서비스 리소스에 연결되기 전에 endpoints라는 리소스에 연결되며 endpoints 리소스 내부적으로는 Addresses 에 등록된 IP만 서비스 리소스에 연결됩니다. 즉, NotReadyAddresses로 등록된 IP는 서비스 리소스에 연결되지 않으며 요청을 받을 수 없는 상태가 됩니다.그리고 readiness probe 에 실패한 파드는 endpoints 리소스의 NotReadyAddresses로 등록됩니다.kubectl describe pod &amp;lt;pod-name&amp;gt;# Name: kubia-readiness-pod# ...# IP: 10.0.45.55kubectl describe endpoints &amp;lt;service-name&amp;gt;# Name: kubia-readiness-clusterip# ...# Subsets:# Addresses: &amp;lt;none&amp;gt;# NotReadyAddresses: 10.0.45.55만약 liveness probe로 파드가 재시작되기 전에 트래픽을 완화하기 위한 용도로 readiness probe를 사용한다면 아래를 주의해야 하여 설정하는 것이 좋습니다. readiness probe는 liveness probe와 다른 엔드포인트로 healthcheck를 진행합니다. readiness probe는 liveness probe보다 먼저 동작해야합니다.결론liveness probe와 startup probe는 파드의 self-healing을 위해서 반드시 사용되어야 하지만 정확하게 이해하지 못한다면 pod가 무분별하게 재시작되어 시스템에 악영향을 줄 수 있기 때문에 조심해야 합니다.readiness probe는 어플리케이션 시작 후 liveness probe의 무분별한 파드 재시작을 억제하기 위해서 사용될 수 있을 것입니다. 이를 위해서 liveness probe와 다른 엔드포인트로 healthcheck를 진행하며 liveness probe보다 먼저 동작하도록 설정해야 합니다." }, { "title": "마이크로서비스 아키텍처 이해하기", "url": "/posts/%EB%A7%88%EC%9D%B4%ED%81%AC%EB%A1%9C%EC%84%9C%EB%B9%84%EC%8A%A4-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0/", "categories": "DevOps", "tags": "DevOps, Architect", "date": "2021-10-07 13:00:00 +0900", "snippet": "Overview이번 글에서는 MSA가 무엇인지를 이해하고, 특징이 무엇인지, 어떤 활용 가치를 가지는 지에 대해서 이야기 해보겠습니다.MSA를 이해하기에 앞서서 MSA가 등장하고 주목받게된 이유에 대해서 설명하기 위해 기존에 사용되던 형태인 Monolithic Architecture에 대해서 살펴보겠습니다.Monolithic ArchitectureMonolithic Architecture는 어플리케이션을 구성하는 서비스(기능)들이 하나의 유닛으로 개발/배포/운영되는 형태입니다.온라인 쇼핑몰 어플리케이션을 예를 들면 주문,계정관리,상품관리 등의 모든 기능을 하나의 Spring 앱으로 개발/배포/운영되는 것입니다. (*Spring 앱 내에서 MVC로 설계하고 기능을 나누어 개발하였더라도 이는 하나의 앱으로 배포되기 때문에 Monolithic Architecture에 포함됩니다.)이러한 방식은 작은 규모의 어플리케이션을 개발하고 운영할 때에 효율적일 수 있으나 규모가 커짐에 따라 여러 문제점들이 발생합니다. 라이브러리 의존성 각 서비스에서 필요한 라이브러리의 버전 충돌이 발생할 수 있습니다. 예를 들면 주문 기능은 XX Library 1.1 버전을 사용하여 개발되었는 데, 상품관리 기능은 XX Library 3.3 버전을 사용하여 개발되었다면 서로 필요한 버전이 다르게 됩니다. 이러한 경우 의존성 문제가 발생하여 어플리케이션을 정상적으로 실행시키지 못할 수 있습니다. 비효율적인 확장 특정 서비스만 사용량이 늘어 확장이 필요한 경우에도 전체 어플리케이션을 확장해야합니다. 이는 수평적 확장이 이뤄질 때 서버에 불필요한 리소스를 잡아먹을 뿐만 아니라, 어플리케이션이 프로비저닝되는 시간이 증가하는 문제도 발생합니다. 예를 들면 주문이 폭주하였을 때 주문 서비스만 확장하는 것이 아닌 전체 쇼핑몰 어플리케이션을 확장해야합니다. 비효율적인 테스트/배포 특정 서비스만 수정하더라도 전체 어플리케이션을 테스트하고 배포해야합니다. 이로 인해 전체적인 개발 프로세스 주기가 느려질 수 있습니다. 장애 전파 특정 서비스(기능)에 장애가 발생할 때 다른 서비스에 전파될 수 있습니다. 장애 전파를 최소화 하기 위해서 개발자가 전체 어플리케이션의 구조와 서비스 간 연관관계를 이해해야 하며 이는 비효율적인 개발로 이어질 가능성이 높습니다. 조직 문화 규모가 큰 어플리케이션을 하나로 관리하게 되면 조직 관리를 위해 역할에 따라 부서가 구분되게 됩니다. (프론트엔드 개발 부서, 백엔드 개발 부서, DBA 부서) 다른 부서와 소통하는 것은 생각보다 쉽지 않으며 공식적인 절차를 거쳐야 합니다. 이는 서로 다른 이해관계, 책임 분산 등으로 인해 부서 간의 의견 충돌, 책임 전가, 느린 피드백 등의 문제를 일으킬 수 있습니다. 그리고 이는 의사결정 및 개발의 지연을 일으키는 좋지 못한 조직 문화를 형성하게 됩니다. 점차 커지는 규모의 어플리케이션에서 이러한 문제점들을 극복하기 위해서 MSA(Microservice Architecture)가 등장하게 되었고 여러 장점들로 인해 관심을 받게 됩니다.Microservice Architecture (MSA)MSA는 어플리케이션을 구성하는 서비스(기능)들을 각각의 유닛으로 개발/배포/운영되는 형태입니다.온라인 쇼핑몰 어플리케이션을 예를 들면 주문 기능을 xx앱으로, 계정관리 기능을 xx앱으로, 상품관리 기능을 xx앱으로 각각 개발/배포/운영되는 것입니다.이는 큰 규모의 어플리케이션에 발생하는 Monolithic Architecture의 문제점들을 해결할 수 있습니다. 라이브러리 의존성 각 서비스(기능)은 독립된 시스템에서 실행되기 때문에 라이브러리 버전의 충돌이 발생하지 않습니다. 효율적인 확장 특정 서비스만 사용량이 늘었다면, 해당 서비스에 대해서만 수평적 확장을 수행할 수 있습니다. 이는 불필요한 서버 리소스를 제거하며, 어플리케이션이 동작을 위해 프로비저닝되는 시간을 줄일 수 있습니다. 효율적인 테스트/배포 특정 서비스만 수정한다면 특정 서비스에 대해서만 테스트하고 배포하면 됩니다. 이는 전체적인 개발 프로세스 주기를 단축시킬 수 있습니다. 장애 전파 X 각 서비스(기능)은 독립된 시스템에서 실행되기 때문에 특정 서비스(기능)에 장애가 발생할 때 다른 서비스에 장애가 전파되지 않습니다. 개발자가 전체 어플리케이션의 구조나 타 서비스의 로직을 이해할 필요가 없습니다. 이는 효율적인 개발로 이어질 수 있습니다. 조직 문화 어플리케이션을 작은 단위의 서비스별로 개발/배포/운영하게 되면 서비스별로 부서를 구분할 수 있습니다. (주문 서비스 부서에 프론트엔드 개발자, 백엔드 개발자, DBA가 전부 소속됩니다.) 같은 부서에서 소통하면 공식적인 절차를 거치지 않고 빠르게 피드백을 받을 수 있습니다. 또한, 다른 서비스와 독립되어 있기 때문에 서비스의 장애는 오롯이 부서의 책임입니다. 이는 부서 간 책임 전가와 같은 조직적 문제를 해결하고, 높은 자율성과 책임성을 가지는 조직 문화를 형성할 수 있습니다. 이는 개발팀과 운영팀이 단일팀으로 병합되어 엔지니어가 개발/테스트/배포/운영까지 작업하는 개념인 devops 를 가능하게 합니다. (two-pizza team 이야기를 참조하여 MSA에서 추구하는 조직문화에 대해 이해할 수 있습니다.) &amp;gt;여기까지 읽으면 MSA를 Monolithic Architecture의 발전된 형태라고 이해할 수 있지만, MSA도 Monolithic Architecture에 비교되는 단점을 가지고 있습니다. 성능 프로세스 내부에서 데이터를 주고 받는 것보다 IPC, RPC, HTTP와 같이 서로 다른 프로세스가 데이터를 주고 받는 것이 더 느립니다. MSA의 경우 각 서비스가 독립된 시스템에서 실행되기 때문에 서비스 간의 데이터를 주고받을 때 오버헤드가 발생합니다. 복잡성 증가 MSA를 성공적으로 구현하기 위해 Service Discvoery, Circuit Breaker 등의 기술을 도입해야하고, 그 구조가 복잡해집니다. 결론각 아키텍처의 장/단점을 명확하게 이해하고 상황에 맞게 적절한 아키텍처를 선택하여 설계하는 것이 중요합니다.위의 특징과 장/단점을 분석해보았을 때, 내부적으로 빠른 동작이 필요하거나 간단한 어플리케이션의 경우 모놀리식 아키텍처로 설계하는 것이 효율적입니다. (마이크로 서비스 아키텍처로 구현할 경우에 내부 동작의 지연이 발생하거나 관리의 복잡성을 가져올 수 있습니다.)반대로, 규모가 크고 복잡하거나 지금은 간단하더라도 확장될 가능성이 있는 어플리케이션은 마이크로 서비스 아키텍처로 설계하여 확장성, 개발주기 단축, 이상적인 개발문화 등의 장점을 가져옴으로써 지속적이고 효율적으로 어플리케이션을 개발/테스트/배포/운영할 수 있습니다." }, { "title": "Python - 임시 파일 다루기 (tempfile)", "url": "/posts/Python-%EC%9E%84%EC%8B%9C-%ED%8C%8C%EC%9D%BC-%EB%8B%A4%EB%A3%A8%EA%B8%B0-(tempfile)/", "categories": "Python", "tags": "Python", "date": "2021-10-04 14:00:00 +0900", "snippet": "Overview저는 아래와 같은 과정(*경험)을 겪으면서 임시파일을 다루는 것에 대한 필요성을 느꼈습니다.Python 기반의 Flask 어플리케이션을 개발하면서… 로컬에서 Unit Test를 진행하고자 했습니다. → 어플리케이션에는 사용자 데이터를 데이터베이스에 저장하는 로직이 포함되어 있었기 때문에 이를 테스트 하기 위해서 테스트용 데이터베이스가 필요했습니다. → 테스트용 데이터베이스는 테스트가 시작될 때 임시적으로 생성되고 테스트가 끝나면 삭제되어 리소스를 낭비하지 않기를 원했습니다. → 테스트용 임시 데이터베이스를 위한 OS상의 임시파일이 필요했습니다.이를 해결하기 위해서 임시파일을 다루는 방법에 대해서 찾아보았고 이번 글에서는 그 내용을 공유하려 합니다.tempfile파이썬에서는 임시파일을 다루기 위해 tempfile 이라는 standard library를 제공합니다. tempfile 에는 여러 메소드가 있으나 그 중 자주 사용되는 mkstemp(), TemporaryFile() 메소드를 살펴봅니다.tempfile.mkstemp()mkstemp() 메소드는 아래와 같은 특징을 가지고 있습니다. 가장 안전한 방식으로 파일을 생성합니다. (파일을 생성한 사용자만 읽을 수 있다.) 사용자가 직접 파일을 삭제해야합니다. 닫히더라도 사용자가 직접 파일을 삭제하기 전까지 임시 파일이 보존됩니다.import tempfileimport osdef read(path): with open(path, &#39;r&#39;) as f: while True: line = f.readline() if not line: break print(line)def write(path, text): with open(path, &#39;w&#39;) as f: f.write(text)def main(): print(&quot;!!! Start working with file&quot;) fd, path = tempfile.mkstemp() # 임시 파일을 생성하고 file descriptor, file path(절대경로)를 반환합니다. print(f&quot;@ Temporary file: {path} {os.path.isfile(path)}&quot;) write(path, &quot;Hello World!&quot;) read(path) os.close(fd) # 파일을 닫습니다. os.unlink(path) # 파일을 삭제합니다. print(&quot;!!! End working with file&quot;) print(f&quot;@ Temporary file: {path} {os.path.isfile(path)}&quot;)if __name__ == &quot;__main__&quot;: main()tempfile.TemporaryFile()TemproaryFile() 메소드는 아래와 같은 특징을 가지고 있습니다. mkstemp() 와 같은 규칙을 사용하여 파일을 안전하게 생성합니다. 파일은 닫히는 즉시 삭제됩니다.import tempfiledef main(): print(&quot;!!! Start working with file&quot;) with tempfile.TemporaryFile(mode=&#39;w+t&#39;) as f: f.write(&#39;Hello World!&#39;) f.seek(0) while True: line = f.readline() if not line: break print(line) print(&quot;!!! End working with file&quot;)if __name__ == &quot;__main__&quot;: main()&amp;gt;두 메소드의 특징을 비교해보았을 때, 임시파일을 여러번 재사용해야하는 경우에 mkstemp() 를 유용하게 사용할 수 있을 것 같고, 그 외에는 TemporaryFile()을 이용하여 임시파일을 사용자의 개입없이 간단하게 삭제할 수 있을 것 같습니다.정확하고 자세한 내용은 공식 홈페이지를 참조하는 것이 좋습니다. https://docs.python.org/3/library/tempfile.html결론임시 파일은 테스트 뿐만 아니라 특정 데이터를 다른 머신으로 전달하기전 버퍼로써 활용되기도 하며, 게시글과 같은 컨텐츠를 임시저장할 때도 사용되는 등 다양한 용도로 활용됩니다. 이러한 여러 활용처에서 tempfile 라이브러리를 활용하여 임시파일을 간단하게 생성하고 삭제할 수 있어야합니다." }, { "title": "Pyhton - TypeError 줄이기 (Function Annotation, MyPy)", "url": "/posts/Pyhton-TypeError-%EC%A4%84%EC%9D%B4%EA%B8%B0-(Function-Annotation,-MyPy)/", "categories": "Python", "tags": "Python", "date": "2021-10-02 16:00:00 +0900", "snippet": "Overview파이썬을 다루다가 보면 실행 중에 갑작스런 TypeError를 접했던 경험이 종종 있었습니다. 이를 몇 번 접하고 나서 Type에 대해 정확하게 이해하고 이러한 오류를 줄일 수 있는 방법을 찾아본 내용을 공유합니다.데이터 타입데이터 타입은 프로그래밍 언어에서 데이터의 형태를 의미합니다. (int, float, string, list, dictionary …)프로그램 상에서 데이터는 메모리에 저장되어 사용됩니다. 데이터 타입은 데이터가 메모리에 저장될 때 확보해야하는 메모리 크기를 결정하고 메모리에 저장되어 있는 2진수를 어떻게 해석할 지에 대해 컴퓨터에게 알려주기 위해 존재합니다. 이를 통해 다양한 데이터 형태를 표현하더라도 메모리 공간을 효율적으로 활용할 수 있습니다.정적 타입 vs 동적 타입정적 타입 : “정적 타입은 개발자가 직접 코드 상에 타입을 지정하며, 컴파일 시 자료형이 결정됩니다.” 이는 타입 에러로 인한 문제점을 조기에 발견하여 프로그램 실행 중 에러가 발생하는 것을 최소화할 수 있습니다. (e.g. Java)동적 타입 : “동적 타입은 개발자가 별도로 타입을 지정하지 않으며, 컴파일 시 자료형이 결정되는 것이 아니라 런타임에 결정됩니다.” 이는 작고 간단한 프로젝트나 스크립트의 개발 속도를 높일 수 있는 요소가 됩니다. (e.g. Python, Javascript)&amp;gt;컴파일 시 에러가 발생하는 것은 개발의 속도를 늦추는 요소가 될 수 있지만, 런타임 에러를 최소화할 수 있는 장점을 가집니다. 이는 런타임 에러 발생 시 큰 영향을 받을 수 있는 대규모 프로젝트를 진행할 때 긍정적으로 생각할 수 있습니다. 반면 동적 타입의 경우 빠른 개발이 필요한 프로젝트나 스크립트에서 긍정적으로 생각할 수 있습니다.약타입 vs 강타입동적 타입 언어는 약타입과 강타입 으로 다시 구분됩니다. 약타입 : 자료형이 맞지 않을 시에 프로그래밍 언어 자체에서 암묵적으로 타입을 변환합니다. (e.g. javascript) 강타입 : 자료형이 맞지 않을 때 에러가 발생합니다. (암묵적 변환을 지원하지 않습니다.) (e.g. python)이해를 위해 아래 예시를 살펴 보면, 자바스크립트의 경우 개발자가 integer 타입으로 사용하기 위해 따옴표 없이 표현했더라도 + operation을 처리하기 위해서 프로그래밍 언어 자체에서 암묵적으로 String 타입으로 변환하여 프로그램을 실행시킵니다. 반면 파이썬의 경우 + operation을 수행할 수 없다며 TypeError 를 발생시킵니다.console.log(1+&quot;1&quot;);// 출력: 11print(1+&quot;1&quot;)# 에러 : TypeError: unsupported operand type(s) for +: &#39;int&#39; and &#39;str&#39;&amp;gt; 약타입 장점 : 런타임 에러를 최소화하여 프로그램이 끝까지 실행되도록 할 수 있습니다. 단점 : 개발자가 원하지 않는 동작을 프로그램에서 실행할 수 있으며, 이러한 동작 오류는 에러가 발생하는 것이 아니기 때문에 찾기가 힘듭니다. 강타입: 장점 : 암묵적 변환이 이뤄지지 않기 때문에 디버깅하기 쉬워집니다. 단점 : 런타임 에러가 발생하여 프로그램이 동작하지 않을 수 있습니다. 실제로 자바스크립트는 동적 타입 중에서도 약타입을 사용하기 때문에 큰 프로젝트에서 단점이 극명하게 드러났습니다. 자바스크립트가 node.js 를 통해 백엔드에서 활용되는 등 다양한 곳에서 활용되고 점차 발전해나가자 이러한 단점을 극복하기 위해 정적 타입을 지원하는 타입스크립트가 개발되었습니다.Duck TypingDuck Typing은 ‘오리처럼 걷고, 오리처럼 꽥꽥거리면, 그것은 틀림없이 오리다.’ 라는 의미를 가지고 있습니다.이는 개발자가 별도로 타입을 지정하지 않고, 프로그래밍 언어가 데이터의 모습을 보고 판단하여 타입을 결정한다는 의미로 해석할 수 있습니다.a = 1b = &quot;1&quot;print(type(a))print(type(b))&amp;lt;class &#39;int&#39;&amp;gt;&amp;lt;class &#39;str&#39;&amp;gt;Python - Function Annotation파이썬은 동적 타입 언어이며 Duck Typing 특징을 가지고 있기 때문에, 데이터 타입에 대한 가독성이 다소 떨어질 수 있습니다. 만약 파이썬으로 다른 개발자와 협업하거나 대규모 프로젝트를 진행할 때에는 가독성을 위해 코드 상에 타입을 명확하게 표현할 수 있는 방법이 필요합니다.Function Annotation은 데이터 타입의 힌트를 제공하며, 이를 통해 코드 상에 타입을 명확하게 표현할 수 있습니다. (**타입을 제한하는 것이 아니라 힌트를 주는 것입니다.)def add(a: int, b: int) -&amp;gt; int: # return type is defined &quot;-&amp;gt; int&quot; return a + bnum_a: int = 1num_b: int = 2add(num_a,num_b)Function Annotation 기능은 Python3 부터 지원하기 시작했으며 이전에는 Comment를 사용하여 타입을 명시 했었습니다.def add(a,b): &quot;&quot;&quot; a: int b: int return type: int &quot;&quot;&quot; return a + bnum_a = 1 # type: intnum_b = 2 # type: intadd(num_a,num_b)저는 기능에 대한 간략한 흐름과 사용하는 이유에 대해 설명하고 있지만 자세한 문법과 사용방법은 공식 홈페이지를 통해 배우는 것이 가장 정확하고 효율적이라고 생각합니다. https://www.python.org/dev/peps/pep-3107/ (Function Annotation) https://docs.python.org/3/library/typing.html (typing - standard library)Pyhthon - MyPy파이썬은 동적 타입 언어이기 때문에 런타임 타입에러가 발생할 수 있습니다. 런타임 에러는 프로그램이 실행 중에 발생하는 에러로써 운영환경에서 발생할 경우 사용자 경험이 낮아질 수 있습니다. 때문에 프로그램 실행 전에 타입에러를 발견하고 조치할 필요가 있습니다.MyPy는 정적 타입 체크를 도와주는 파이썬의 Standard Library 입니다. (정적 테스트는 프로그램 실행 전에 코드를 기반으로 테스트를 진행하는 테스트 기법입니다.) 예시를 통해 어떻게 동작하는 간단하게 살펴봅니다.MyPy Library 설치 python3 -m pip install mypy만약 타입 에러가 발생하지 않는 코드를 mypy를 통해 테스트해보면 아래와 같이 성공 메시지를 반환받습니다.type_python.pydef add(a: int, b: int) -&amp;gt; int: return a + bnum_a: int = 1num_b: int = 2add(num_a, num_b)python3 -m mypy type_python.py# Success: no issues found in 1 source file만약 타입 에러가 포함된 코드를 테스트하면 아래와 같이 실패 메시지와 에러가 발생하는 시점을 확인할 수 있습니다.type_python.pydef add(a: int, b: int) -&amp;gt; int: return a + bnum_a: int = 1num_b: str = &quot;a&quot;add(num_a, num_b)python3 -m mypy type_python.py# type_python.py:7: error: Argument 2 to &quot;add&quot; has incompatible type &quot;str&quot;; expected &quot;int&quot;# Found 1 error in 1 file (checked 1 source file)Function Annotation과 같은 맥락으로 자세한 내용은 공식 홈페이지를 참조합니다. https://github.com/python/mypy (Github) https://mypy.readthedocs.io/en/stable/index.html# (ReadHat)결론파이썬을 사용할 때에는 Function Annotation을 통해 타입을 코드 상에 표현하여 가독성을 높이고 MyPy Library를 사용하여 프로그램을 실행하기 전에 사전에 타입에러를 발견하고 조치하여 런타임 에러를 최소화하는 노력이 필요합니다." }, { "title": "Python - OOP 정보은닉에 대한 고민 (Name Mangling, Property)", "url": "/posts/Python-OOP-%EC%A0%95%EB%B3%B4%EC%9D%80%EB%8B%89%EC%97%90-%EB%8C%80%ED%95%9C-%EA%B3%A0%EB%AF%BC-(Name-Mangling,-Property)/", "categories": "Python", "tags": "Python", "date": "2021-10-01 18:00:00 +0900", "snippet": "Overview파이썬을 OOP 방식으로 사용하려고 살펴보다가 문득 “파이썬은 접근제어자가 없는 데 어떤 방식으로 정보은닉을 만족시킬 수 있을까??” 라는 고민을 시작하게 되었습니다. 이번 글에서는 위 질문에 대답하기 위해 찾아본 내용을 공유하려 합니다.우선 정보은닉이 무엇인지 이해할 필요가 있습니다. OOP에서는 연관 있는 데이터와 함수를 클래스로 묶고, 구현 내용을 외부에 감추는 것을 캡슐화라고 하며 캡슐화된 클래스에서 중요한 데이터나 기능을 외부에서 접근하지 못하도록 구성하는 것을 정보은닉이라고 합니다. 이를 통해 외부에서 함부로 데이터를 읽거나 변경하지 못하고 개발자가 원하는 범위 안의 동작만 수행하도록 제한하여 보안성을 높이고 에러를 최소화할 수 있습니다.Name Mangling가장 먼저 찾을 수 있던 내용이 Name Mangling입니다. Name Mangling은 Java의 접근제어자와 비교하여 설명하는 경우가 많았기 때문에 “접근제어자와 비슷한 역할인 건가??” 라는 생각으로 살펴보았습니다. (전혀 다른 의미였지만요… ㅎㅎ…)Name Mangling은 함수나 변수명을 컴파일 단계에서 컴파일러가 일정한 규칙을 가지고 변형하는 것을 의미합니다. (*Name Decoration이라고도 합니다.) 파이썬에서는 _ 또는 __를 변수 또는 함수앞에 접미사로 붙여서 사용할 수 있습니다.Name Mangling은 다른 범위에 있는 같은 이름 함수나 변수를 구별하기 위한 목적으로 사용됩니다. (예를 들면 하위 클래스에서 상속받은 변수와 같은 이름의 변수를 사용할 때…) 사실 굳이 왜 이렇게 사용해야하는 지 이해가 잘 안되어서 예시를 하나 들어봤습니다.전기차를 상속을 통해 구현할 때 자동차 등록코드와 전기차 등록코드를 모두 등록해야된다고 가정해봅니다. 적절한 변수명이 code라고 했을 때 자동차 등록코드가 전기차 등록코드로 오버라이딩 되어 버립니다. 완벽히 이해하지 않아도 되니 잠깐 살펴봅니다.class Car: def __init__(self, code): self.code = codeclass ElectricCar(Car): def __init__(self, code): self.code = codetesla = ElectricCar(&quot;xxxxxxxxxx&quot;)print(tesla.__dict__){&#39;code&#39;: &#39;xxxxxxxxxx&#39;}이럴 때 Name Mangling을 활용하면 파이썬 컴파일러가 _클래스명__변수명으로 변수명을 변경시킵니다. 결과적으로 같은 이름의 __code 변수명을 사용했음에도 오버라이딩 되지 않습니다.class Car: def __init__(self, code): self.__code = codeclass ElectricCar(Car): def __init__(self, car_code, code): self._Car__code = car_code self.__code = codetesla = ElectricCar(&quot;xxxxxxxxxx&quot;,&quot;zzzzzzzzzzz&quot;)print(tesla.__dict__){&#39;_Car__code&#39;: &#39;xxxxxxxxxx&#39;, &#39;_ElectricCar__code&#39;: &#39;zzzzzzzzzzz&#39;}그리고 처음에 정보은닉을 위해 활용된다고 헷갈렸던 포인트(개념)을 정리해봅니다.class Person: def __init__(self,name,age): self.name = name self.age = age self.__secret = &quot;zxj412mazasxio5n321&quot;person = Person(&quot;Lee&quot;,26)print(person.name)print(person.age)print(person.__secret) # __secret 속성이 없다는 에러가 출력됩니다.Lee26Traceback (most recent call last): ....AttributeError: &#39;Person&#39; object has no attribute &#39;__secret&#39;위 코드를 실행시켜보면 __secret 속성이 없다는 에러가 출력됩니다. 이 것은 속성에 접근이 불가능하여 발생하는 에러가 아니라 속성의 이름을 컴파일러에서 바꿨기 때문에 발생하는 에러입니다.class Person: def __init__(self,name,age): self.name = name self.age = age self.__secret = &quot;zxj412mazasxio5n321&quot;person = Person(&quot;Lee&quot;,26)print(person.name)print(person.age)# print(person.__secret) # __secret 속성이 없다는 에러가 출력됩니다.print(person.__dict__)Lee26{&#39;name&#39;: &#39;Lee&#39;, &#39;age&#39;: 26, &#39;_Person__secret&#39;: &#39;zxj412mazasxio5n321&#39;}실제로 위 코드를 실행시켜보면 _Person__secret 이라는 속성이 person 객체에 포함되어 있는 것을 확인할 수 있습니다. 파이썬 컴파일러가 컴파일 단계에서 __secret 속성의 이름을 _Person__secret 으로 변경시킨 것입니다.그리고 아래 코드를 실행시켜보면 변경된 속성의 이름으로 접근할 수 있는 것을 확인할 수 있습니다. 단순히 속성의 이름만 변경된 것이기 때문에 변경된 속성 이름으로 접근하면 데이터를 읽거나 변경할 수 있는 것입니다. 결론적으로 Name Mangling은 완벽하게 정보은닉을 만족시킬 수 없습니다.class Person: def __init__(self,name,age): self.name = name self.age = age self.__secret = &quot;zxj412mazasxio5n321&quot;person = Person(&quot;Lee&quot;,26)print(person.name)print(person.age)# print(person.__secret) # __secret 속성이 없다는 에러가 출력됩니다.# print(person.__dict__)print(person._Person__secret)Lee26zxj412mazasxio5n321Property그리고 찾아볼 수 있었던 것은 property 데코레이터입니다. property 데코레이터은 getter/setter를 간단하게 생성해주는 파이썬의 기본 데코레이터입니다.Java에서는 접근 제어자를 통해 데이터에 직접 접근하지 못하도록 보호하고 데이터를 읽거나 수정하는 메소드만 노출시키는 방식으로 정보 은닉을 만족시킵니다. 여기서 데이터를 읽는 메소드를 getter, 데이터를 수정하는 메소드를 setter라고 표현합니다. getter/setter를 활용하면 객체의 데이터를 읽거나 수정할 때 타입체크를 하거나 인증된 사용자인지 확인하는 등의 작업을 수행하여 데이터를 안전하게 보호할 수 있습니다.property 데코레이터 사용하지 않을 경우class Person: def __init__(self, name, age): self.name = name self.set_age(age) def get_age(self): return self.__age def set_age(self, age): if type(age) is not int: raise TypeError(&quot;age must be int type&quot;) else: self.__age = ageperson = Person(&quot;Lee&quot;,24)print(person.get_age())person.set_age(50)print(person.get_age())2450property 데코레이터 사용class Person: def __init__(self, name, age): self.name = name self.age = age @property def age(self): return self.__age @age.setter def age(self, age): if type(age) is not int: raise TypeError(&quot;age must be int type&quot;) else: self.__age = ageperson = Person(&quot;Lee&quot;,24)print(person.age)person.age = 50print(person.age)2450하지만 property 데코레이터도 결국 Name Mangling을 사용하는 방식이기 때문에 Name Mangling 원리로 변경된 변수명으로 데이터에 직접 접근할 수 있습니다. 결국 property를 사용하더라도 완벽하게 정보 은닉을 만족할 수 없습니다.class Person: def __init__(self, name, age): self.name = name self.set_age(age) self.auth = True def get_age(self): if self.auth: # 신뢰하는 사람만 데이터에 접근할 수 있습니다. (*가정) return self.__age else: raise AttributeError(&quot;Access Denied&quot;) def set_age(self, age): if type(age) is not int: # 나이는 int type이어야 합니다. raise TypeError(&quot;Must be int type for &#39;age&#39;&quot;) else: self.__age = ageperson = Person(&quot;Lee&quot;,24)print(person.get_age())person._Person__age = &quot;HHHHH&quot;print(person._Person__age)24HHHHH결론제가 찾아본 한에서 파이썬은 완벽하게 정보은닉을 만족할 수 없습니다. 하지만 Name Mangling과 Property 데코레이터를 적절히 활용하여 최대한 외부에서 간섭하지 못하도록 노력하는 것이 필요합니다." }, { "title": "블로그 Google Analytics 연동하여 사용자 수 파악하기", "url": "/posts/%EB%B8%94%EB%A1%9C%EA%B7%B8-Google-Analytics-%EC%97%B0%EB%8F%99%ED%95%98%EC%97%AC-%EC%82%AC%EC%9A%A9%EC%9E%90-%EC%88%98-%ED%8C%8C%EC%95%85%ED%95%98%EA%B8%B0/", "categories": "Blog-management", "tags": "Blog-management", "date": "2021-09-30 15:00:00 +0900", "snippet": "OverviewGA(Google Analytics) 는 웹 페이지 또는 모바일 어플리케이션 사용자의 접근 기록이나, 행동 데이터들을 수집하고 분석하는 툴입니다.실적을 계산하거나 웹 사이트/모바일 어플리케이션을 개선시키는 등의 다양한 용도로 활용되지만 저는 단순히 제 블로그의 접근하는 분들이 얼마나 될까? 라는 궁금증을 해결하기위해서 활용해보았습니다. ㅎㅎ…Google Analytics 생성Google 계정으로 로그인하여 Google Analytics 페이지에서 측정 시작을 통해 초기 설정을 진행할 수 있습니다. https://analytics.google.com (Google Analyitcs)위 스텝을 성공적으로 진행하면 계정(piou987), Universal Analytics 속성(wsscc2021.github.io), Google Analytics 4 속성(wsscc2021.github.io - GA4)이 생성됩니다._config.yml 파일 수정웹페이지 접속 시 Google Analytics로 데이터를 보내기 위해서는 별도의 HTML+JS를 작성해야하지만, 제가 사용하는 테마에는(Jekyll-theme-chirpy) 기능이 이미 구현되어 있어서 _config.yml 파일에 Analytics ID만 입력하면 사용할 수 있었습니다.Google Analytics 4 속성의 웹 스트림 ID를 복사하여 _config.yml파일에 붙여넣습니다.google_analytics: id: &#39;G-2Y7BLPLM54&#39; # fill in your Google Analytics ID # Google Analytics pageviews report settings pv: proxy_endpoint: # fill in the Google Analytics superProxy endpoint of Google App Engine cache_path: # the local PV cache data, friendly to visitors from GFW regionGoogle Analytics Developer Page만약 테마에 기능이 구현되어 있지 않다면 Google Analytics의 Developer 페이지를 참조하면 좋을 것 같습니다. https://developers.google.com/analytics/devguides/collection/gtagjs동작 확인변경한 내용을 반영한 뒤 블로그에 접근해보면, Google Analytics에 사용자 수가 집계되는 것을 볼 수 있습니다.Page ViewGCP(Google Cloud Platform)의 App Engine을 사용하여 Google Analytics 의 Report를 노출시키고 이를 기반으로 Page view 기능도 활용할 수 있습니다.하지만 나중에 사용자 수가 많아져서 App Engine 비용이 발생하게 될까 싶어 활용하지 않으려 합니다.무엇보다 Google Analytics에서 잘 분석하면 얻을 수 있는 정보라서… 크게 쓸모가 없다고 생각했습니다." }, { "title": "블로그 댓글 기능 추가하기 with Disqus", "url": "/posts/%EB%B8%94%EB%A1%9C%EA%B7%B8-%EB%8C%93%EA%B8%80-%EA%B8%B0%EB%8A%A5-%EC%B6%94%EA%B0%80%ED%95%98%EA%B8%B0-with-Disqus/", "categories": "Blog-management", "tags": "Blog-management", "date": "2021-09-30 11:00:00 +0900", "snippet": "OverviewJekyll 로 만든 “정적”웹페이지는 댓글 추가/삭제/수정과 같은 동적인 작업을 수행하지 못합니다. 때문에 댓글 서비스를 별도로 구축해야하는 데, 직접 구축하기 보다는 완성된 서비스를 제공해주는 Disqus를 활용하는 것이 간편합니다. 이번 글에서는 제 블로그에 Disqus를 적용했던 내용을 적으려 합니다. Jekyll + Github.io Jekyll-theme-chirpy DisqusDisqus Site 생성댓글 기능을 위해 Disqus Site를 생성해야 합니다. Disqus 홈페이지에 로그인 한 뒤 Get Started를 통해 간단하게 사이트를 추가할 수 있습니다. https://disqus.com/ (Disqus)_config.yml 파일 수정Disqus 서비스를 웹페이지에서 사용하기 위해서는 별도의 HTML+JS를 작성해야하지만, 제가 사용하는 테마에는(Jekyll-theme-chirpy) 기능이 이미 구현되어 있어서 _config.yml 파일에 Shortname만 입력하면 사용할 수 있었습니다.추가된 Disqus Site의 정보를 확인하여 Shortname을 복사하고 _config.yml 의 disqus 설정값에 붙여넣습니다._config.ymldisqus: comments: true # boolean type, the global switch for posts comments. shortname: &#39;wsscc2021-github-io&#39; # Fill with your Disqus shortname. › https://help.disqus.com/en/articles/1717111-what-s-a-shortname적용된 내용 확인위와 같이 설정한 뒤 블로그 게시글의 맨 마지막으로 넘어가 확인해보면, 아래와 같이 Disqus 서비스가 제공해주는 댓글 기능을 활용할 수 있는 상태가 되어 있습니다.Disqus embed code만약 다른 Theme를 사용하고 있어서 Disqus 기능이 구현이 안되어 있고 직접 코드를 작성해야한다면 Disqus Help 페이지를 참조하면 좋을 것 같습니다. https://help.disqus.com/en/articles/1717112-universal-embed-code" }, { "title": "블로그 시작하기", "url": "/posts/%EB%B8%94%EB%A1%9C%EA%B7%B8-%EC%8B%9C%EC%9E%91%ED%95%98%EA%B8%B0/", "categories": "Blog-management", "tags": "Blog-management", "date": "2021-09-29 21:00:00 +0900", "snippet": "Blog Platform 선정블로그를 시작해야겠다고 결심한 순간 블로그를 만드는 방법에 대해서 찾아보았습니다. 처음에는 “블로그 플랫폼은 거기서 거기 아닌가??” 라고 생각했지만 생각보다 다양한 블로그 플랫폼이 존재했고, 각 플랫폼이 장/단점이 명확하게 드러나서 어느 플랫폼을 사용하는 게 좋을 지 고민해야 했습니다. 그리고 저는 블로그를 시작하는 것이 처음이기 때문에 개인적인 경험에 의존하지 않고 각 플랫폼을 사용해보신 다른 분들의 후기를 기반으로 결정했습니다.우선, 블로그 플랫폼을 선정하기 위해 이상적인 블로그의 특징에 대해서 고민하고 정리했습니다. 장기적으로 운영될 것을 고려하여 커스텀이 유연해야 한다. 블로그가 장기적으로 운영되면 추가적으로 필요한 기능이 발견될 수 있습니다. 떄문에 다양한 기능을 지원하거여 plug-in형태로 추가할 수 있거나 직접 개발하여 기능을 추가할 수 있어야한다고 생각했습니다. 비용 부담 최소화 한다. 당연히 돈이 안들어가면 좋겟죠…? 무료로 운영이 가능하다면 가장 좋지만 경우에 따라 연간 10만원까지는 투자할 생각이 있었습니다. Markdown Format으로 작성할 수 있어야 한다. md(markdown)파일은 어느 플랫폼에서나 읽을 수 있고, 작성하기 간단하기 때문에 지금도 문서 정리에 사용하고 있습니다. 블로그 작성만을 위해 다른 에디터를 사용하고 싶지 않았습니다.이를 토대로 여러 블로그 플랫폼을 살펴보았고, 고민 끝에 비용과, 유연한 커스텀 측면을 고려하여 Jekyll + Github.io 조합을 사용하기로 결정했습니다. Medium : 간단하게 생성이 가능하고 무료이지만… 커스텀이 되지 않았습니다 Velog : 22 간단하게 생성이 가능하고 무료이지만… 커스텀이 되지 않았습니다. Wordpress : 포트폴리오, 개발일지, 기술 블로그 등의 다양한 템플릿이 존재했고, 기능도 다양하며 커스텀도 가능합니다. 하지만 1개월 당 $4 비용 부담이 있습니다. Jekyll + Github.io : 코드를 직접 작성하여 정적 웹페이지를 생성하는 형태이기 때문에 커스텀이 상당히 유기적이며, Github.io는 Public Repository 형태라면 무료로 운영할 수 있습니다. (Jekyll : 정적 사이트 생성기, Github.io : 웹페이지를 퍼블리싱하기 위한 용도. (무료))Jekyll 설치Jekyll은 Vue, React처럼 정적 사이트를 만들어주는 도구(혹은 프레임워크)이며 블로그 지향적이기 때문에 테마와 플러그인이 다양하고 풍부합니다. 이러한 특징 때문에 블로그, 포트폴리오 같은 정적 페이지를 만들 때 주로 사용됩니다. https://jekyllrb-ko.github.io/ (Jekyll Official Page)Jekyll은 Ruby기반으로 동작하기 때문에 Ruby 관련 패키지를 설치해야 하며, 빌드를 위해서 GCC, MAKE 패키지를 설치해야 합니다. 현재 글을 쓰는 시점에서의 요구사항은 아래와 같지만, 정확한 요구사항과 설치 방법은 Official page를 참고하는 것이 좋습니다.Jekyll Requirements (2021.09.30 기준) Ruby version 2.5.0 or higher, including all development headers (check your Ruby version using ruby -v) RubyGems (check your Gems version using gem -v) GCC and Make (check versions using gcc -v,g++ -v, and make -v)공식 페이지 내용을 기반으로 간단하게 설치 방법을 정리해보겠습니다. (아래 내용은 Ubuntu 배포판을 기준으로 하며 공식 페이지 내용을 발췌하였습니다.)Ruby와 다른 전제조건을 설치합니다.sudo apt-get updatesudo apt-get install ruby-full build-essential zlib1g-devgem설치 경로를 현재 사용자 홈 디렉터리 아래의 gems 위치로 변경합니다. (*환경변수 및 ~/.bashrc파일을 사용)echo &#39;# Install Ruby Gems to ~/gems&#39; &amp;gt;&amp;gt; ~/.bashrcecho &#39;export GEM_HOME=&quot;$HOME/gems&quot;&#39; &amp;gt;&amp;gt; ~/.bashrcecho &#39;export PATH=&quot;$HOME/gems/bin:$PATH&quot;&#39; &amp;gt;&amp;gt; ~/.bashrcsource ~/.bashrc마지막으로 Jekyll과 bundler를 설치합니다.gem install jekyll bundlerJeklly Theme 선정저는 모든 기능을 개발하여 사용하기보다는 공개 테마를 적극적으로 활용하였습니다. 모든 기능을 개발하다보면 글을 쓰는 시간보다 기능을 개발하고 유지보수하는 것에 시간이 많이 들어갈 것 같았기 때문입니다.테마는 Jekyll-theme-chirpy를 사용하였습니다. 무료, 깔끔한 UI, 필요한 기능들(댓글,검색,태그 분류)을 내포하고 있기 때문에 선택하였습니다. (무료 테마 중에는 만족하는 테마가 많지 않아서 꽤 오래 찾았던 것 같네요.) 테마 검색 사이트 http://jekyllthemes.org/ https://jekyllthemes.io/free jekyll-theme-chirpy https://github.com/cotes2020/jekyll-theme-chirpy (Github) https://chirpy.cotes.info/ (Live demo) Jekyll Theme Chirpy 다운로드제가 선택한 Jekyll Theme Chirpy를 Github Repository에서 다운로드 받고 실행시켜봅니다. 물론 Github Repository READMD파일에 자세하게 정리되어 있으므로 이를 참조하는 것이 가장 좋습니다. https://github.com/cotes2020/jekyll-theme-chirpyGit clonegit clone https://github.com/cotes2020/jekyll-theme-chirpy.gitGemfile의 내용을 기반으로 소스코드를 bundling합니다. (Chirpy테마의 경우 _site 경로에 bundling된 파일들을 저장합니다.)cd jekyll-theme-chirpy bundle installJekyll 실행해봅니다. (저는 WSL을 사용하기 때문에 호스트 윈도우OS에서 접근가능하도록 --host 옵션을 주었습니다.)bundle exec jekyll serve --host=0.0.0.0실행한 뒤 4000포트로 접근하면 블로그가 보입니다. *(이를 활용해서 github에 업로드 전에 이미지가 깨지진 않는 지, 글자 폰트는 적절한지 등의 내용을 검토해볼 수 있습니다.)Github 업로드이제 github을 활용하여 github.io 페이지를 생성하고 Jekyll을 통해 만든 블로그를 업로드합니다.github repository 생성 username.github.io 이름으로 repository를 생성합니다. Repository는 공개 범위가 Public 으로 설정되어야합니다. (Private으로 설정하면 page 개설에 비용을 부과 해야합니다.)github.io 페이지를 생성하기 위해서 초기화 스크립트를 수행합니다. 명령을 수행하면 특정 디렉터리와 파일이 삭제되니 유의합니다. .travis.yml files under _posts folder docsbash tools/init.sh로컬에서 Git 프로젝트의 remote(origin)를 제 Repository로 변경합니다.git remote remove origin git remote add origin https://github.com/wsscc2021/wsscc2021.github.io.gitGithub repository에 push 합니다.git push origin masterGithub repository에 push하면 자동으로 빌드/배포가 수행되는 것을 Action 탭에서 확인할 수 있습니다.그리고 빌드/배포의 결과로 gh-pages branch를 생성하고 bundling된 파일들을 commit한 것을 볼 수 있습니다.마지막으로 github pages의 source branch를 gh-pages branch로 변경하여 퍼블리싱합니다.완료되면 웹브라우저에서 wsscc2021.github.io 로 접근하여 블로그를 확인할 수 있습니다." } ]
